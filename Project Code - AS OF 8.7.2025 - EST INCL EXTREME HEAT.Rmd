---
title: "Virginia yields"
author: "Group 2"
date: "2025-07-01"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```


```{r}
# Load required libraries
library(tidyverse) 
library(ggplot2)    
library(lubridate)  
library(caret)
library(fable)
library(forecast)
library(stargazer)
library(janitor)
library(tibble)

```




```{r}

# Virginia field crop general condition reports
# https://quickstats.nass.usda.gov/

field <- read.csv('https://drive.google.com/uc?id=1XFpXjZ1aZljRaKmz8XMaoqiuz11fHeN9') %>% 
  select('Week.Ending', Period, State, 'Data.Item', Value)

field


```

```{r}

field_wide <- field %>% pivot_wider(names_from = 'Data.Item',
                                    values_from = Value)

field_wide


```


```{r}

temp <- read.table('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-tmpcst-v1.0.0-20250707')

colnames(temp) <- c('Code', 
                'Jan_temp',
                'Feb_temp', 
                'Mar_temp',
                'Apr_temp',
                'May_temp',
                'Jun_temp',
                'Jul_temp',
                'Aug_temp', 
                'Sep_temp',
                'Oct_temp', 
                'Nov_temp', 
                'Dec_temp')

temp_va <- temp %>% filter(str_detect(as.character(Code), '44002'))
temp_va <- temp_va %>% 
  mutate(Year = str_sub(as.character(Code), start = -4),
         State = "VIRGINIA") %>% 
  mutate(Year = as.numeric(Year)) %>% 
  filter(Year > 1979)


```


```{r}

prec <- read.table('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-pcpnst-v1.0.0-20250707')

colnames(prec) <- c('Code', 
                'Jan_prec',
                'Feb_prec', 
                'Mar_prec', 
                'Apr_prec', 
                'May_prec',
                'Jun_prec',
                'Jul_prec', 
                'Aug_prec',
                'Sep_prec',
                'Oct_prec', 
                'Nov_prec',
                'Dec_prec')

prec_va <- prec %>% filter(str_detect(as.character(Code), '44001'))
prec_va <- prec_va %>% 
  mutate(Year = str_sub(as.character(Code), start = -4),
         State = "VIRGINIA") %>% 
  mutate(Year = as.numeric(Year)) %>% 
  filter(Year > 1979)


```

```{r}

sp01 <- read.table('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-sp01st-v1.0.0-20250707')

colnames(sp01) <- c('Code', 
                'Jan_sp01', 
                'Feb_sp01', 
                'Mar_sp01', 
                'Apr_sp01', 
                'May_sp01', 
                'Jun_sp01', 
                'Jul_sp01',
                'Aug_sp01',
                'Sep_sp01',
                'Oct_sp01', 
                'Nov_sp01', 
                'Dec_sp01')

sp01_va <- sp01 %>% filter(str_detect(as.character(Code), '44071'))
sp01_va <- sp01_va %>% 
  mutate(Year = str_sub(as.character(Code), start = -4),
         State = "VIRGINIA") %>% 
  mutate(Year = as.numeric(Year)) %>% 
  filter(Year > 1979)




```

```{r}

phdi <- read.table('https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-phdist-v1.0.0-20250707')

colnames(phdi) <- c('Code', 
                'Jan_phdi', 
                'Feb_phdi', 
                'Mar_phdi', 
                'Apr_phdi', 
                'May_phdi', 
                'Jun_phdi', 
                'Jul_phdi',
                'Aug_phdi',
                'Sep_phdi',
                'Oct_phdi', 
                'Nov_phdi', 
                'Dec_phdi')

phdi_va <- phdi %>% filter(str_detect(as.character(Code), '44006'))
phdi_va <- phdi_va %>% 
  mutate(Year = str_sub(as.character(Code), start = -4),
         State = "VIRGINIA") %>% 
  mutate(Year = as.numeric(Year)) %>% 
  filter(Year > 1979)


```


```{r}

# Virginia corn harvest and yield
# https://quickstats.nass.usda.gov/

corn <- read.csv('https://drive.google.com/uc?id=1vLCIQOVkeEfxCKr4GfTDKVRsJtBfgz-n') %>% 
  select(Year, Period, State, 'Data.Item', Value) %>% 
  filter(State == "VIRGINIA" & Period == "YEAR")

corn


```

```{r}
# working dataset

# Merging datasets
corn_test <- corn %>% filter(Data.Item == "CORN, GRAIN - YIELD, MEASURED IN BU / ACRE") %>% 
  left_join(temp_va, by = c("Year", "State"))
corn_test <- left_join(corn_test, prec_va, by = c("Year", "State"))
corn_test <- left_join(corn_test, sp01_va, by = c("Year", "State"))
corn_test <- left_join(corn_test, phdi_va, by = c("Year", "State"))


# Creating squared precipitation variables
corn_test <- corn_test %>% 
  mutate(Jun_prec_sq = Jun_prec^2, 
         Jul_prec_sq = Jul_prec^2, 
         Aug_prec_sq = Aug_prec^2)

# Merging with merged_wide and filtering
# soybean_test_wide <- left_join(soybean_test, field_wide, by = c("Year", "State"), all = TRUE)
# soybean_test_wide <- soybean_test_wide[soybean_test_wide$State == "VIRGINIA" & soybean_test_wide$Year < 2025]

# Removing columns with any NA values
# soybean_test_wide <- soybean_test_wide[, colSums(is.na(soybean_test_wide)) == 0]

# Split training and testing datasets
corn_test_A <- corn_test %>%  filter(Year < 2021)
corn_test_B <- corn_test %>%  filter(Year > 2020)

```


```{r}

vars <- colnames(corn_test)

corn_replicate <- corn_test %>%  select('Year', 
                                          'Period',
                                          'State', 
                                          'Data.Item', 
                                          'Value', 
                                          'Jul_temp', 
                                          'Jul_prec', 
                                          'Jul_prec_sq', 
                                          'Jun_sp01', 
                                          'Jul_sp01')


```

```{r}

rep_vars <- c('Jul_temp', 
              'Jul_prec', 
              'Jul_prec_sq',
              'Jun_sp01', 
              'Jul_sp01')


y = corn_replicate %>%  select(Value)
X = corn_replicate %>%  select(rep_vars)

# X = sm.add_constant(X)

model = lm(Value ~ Jul_temp + Jul_prec + Jul_prec_sq + Jun_sp01 + Jul_sp01, corn_replicate)


summary(model)

stargazer(model, type = "text", digits = 2, title = "Linear Regression Results")



```

```{r}

results <- predict(model, X)

corn_replicate_accuracy <- corn_replicate %>% cbind(results)

corn_replicate_accuracy %>% 
  ggplot(aes(x = Year, y = as.numeric(Value))) + 
  geom_line() + 
  geom_line(aes(y = results)) + 
  labs(title = "Westcott & Jewison - model replication in VA",
       x = "Year",
       y = "Yield (bu/ac)") + 
  theme_classic()


```

```{r}

corn_replicate_accuracy <- corn_replicate_accuracy %>% 
  mutate(AE = abs(as.numeric(Value) - results),
         APE = abs((as.numeric(Value) - results) / as.numeric(Value) * 100))

paste0("Mean Absolute Error: ", mean(corn_replicate_accuracy$AE))

paste0("Mean Absolute Percentage Error: ", mean(corn_replicate_accuracy$APE))

```

```{r}

y_test = corn_test_A %>%  select(Value)
X_test = corn_test_A %>%  select(rep_vars)

# X = sm.add_constant(X)

model_test = lm(Value ~ Jul_temp + Jul_prec + Jul_prec_sq + Jun_sp01 + Jul_sp01, corn_test_A)


summary(model_test)

```

```{r}

results_test_A <- predict(model_test, X_test)

corn_test_A_accuracy <- corn_test_A %>% cbind(results_test_A)

corn_test_A_accuracy %>% 
  ggplot(aes(x = Year, y = as.numeric(Value))) + 
  geom_line() + 
  geom_line(aes(y = results_test_A, colour = "red")) + 
  labs(title = "Model revision - train set",
       x = "Year",
       y = "Yield (bu/ac)") + 
  theme_classic()

#

corn_test_A_accuracy <- corn_test_A_accuracy %>% 
  mutate(AE = abs(as.numeric(Value) - results_test_A),
         APE = abs((as.numeric(Value) - results_test_A) / as.numeric(Value) * 100))

paste0("Mean Absolute Error: ", mean(corn_test_A_accuracy$AE))

paste0("Mean Absolute Percentage Error: ", mean(corn_test_A_accuracy$APE))




```

```{r}

results_test_B <- predict(model_test, corn_test_B)

corn_test_B_accuracy <- corn_test_B %>% cbind(results_test_B)

corn_test_B_accuracy %>% 
  ggplot(aes(x = Year, y = as.numeric(Value))) + 
  geom_line() + 
  geom_line(aes(y = results_test_B, color = "red")) + 
    labs(title = "Model revision - test set",
       x = "Year",
       y = "Yield (bu/ac)") + 
  theme_classic()


#

corn_test_B_accuracy <- corn_test_B_accuracy %>% 
  mutate(AE = abs(as.numeric(Value) - results_test_B),
         APE = abs((as.numeric(Value) - results_test_B) / as.numeric(Value) * 100))

paste0("Mean Absolute Error: ", mean(corn_test_B_accuracy$AE))

paste0("Mean Absolute Percentage Error: ", mean(corn_test_B_accuracy$APE))


```


```{r}

set.seed(320)

# Recursive feature elimination with cross-validation
X <- corn_test_A %>% select(all_of(vars)) %>% mutate_all(as.numeric) %>% 
  select(-c(Value, Period, State, Data.Item, Code.x, Code.y, Code.x.x, Code.y.y))
y <- corn_test_A %>% pull(Value) %>% as.numeric()

# Define the control for RFE with time series cross-validation
ctrl <- rfeControl(
  functions = lmFuncs,
  method = "cv",
  number = 5,
  verbose = FALSE
)

# Perform RFE with cross-validation
rfecv <- rfe(
  x = X,
  y = y,
  sizes = 1:ncol(X),
  rfeControl = ctrl,
  metric = "MAE"
)

# Extract optimal features
optimal_features <- predictors(rfecv)
cat("Optimal features:", optimal_features, "\n")
cat("Number of optimal features:", rfecv$optVariables %>% length(), "\n")

# Select optimal features for final model
X_optimal <- X %>% select(all_of(optimal_features))

# Train final linear model
final_model <- train(
  x = X_optimal,
  y = y,
  method = "lm",
  trControl = trainControl(method = "none")
)

# Make predictions and calculate metrics
predictions <- predict(final_model, X_optimal)
mae <- mean(abs(y - predictions))
mape <- mean(abs((y - predictions) / y)) * 100

paste0("Mean Absolute Error on training data:", mae)
paste0("Mean Absolute Percentage Error on training data:", mape)

final_model$finalModel

summary(final_model)

stargazer(final_model$finalModel, type = "text", digits = 2, title = "Linear Regression Results")


```

```{r}

corn_test_A2 <- corn_test_A %>% cbind(predictions)

corn_test_A2 %>% ggplot(aes(x = Year, y = as.numeric(Value))) + 
  geom_line() + 
  geom_line(aes(y = predictions, color = "red")) + 
  labs(title = "Model optimization - train set",
       x = "Year",
       y = "Yield (bu/ac)") + 
  theme_classic()




```

```{r}

predictionsB <- predict(final_model, corn_test_B)

corn_test_B_accuracy <- corn_test_B %>% cbind(predictionsB)

corn_test_B_accuracy %>% 
  ggplot(aes(x = Year, y = as.numeric(Value))) + 
  geom_line() + 
  geom_line(aes(y = predictionsB, colour = "Red")) + 
  labs(title = "Model optimization - test set",
       x = "Year",
       y = "Yield (bu/ac)") + 
  theme_classic()

#

corn_test_B_accuracy <- corn_test_B_accuracy %>% 
  mutate(AE = abs(as.numeric(Value) - predictionsB),
         APE = abs((as.numeric(Value) - predictionsB) / as.numeric(Value) * 100))

paste0("Mean Absolute Error: ", mean(corn_test_B_accuracy$AE))

paste0("Mean Absolute Percentage Error: ", mean(corn_test_B_accuracy$APE))
  

```


```{r}

VA_select <- lm(Value ~ Jul_prec + Jul_prec_sq + Jul_sp01, corn_test_A)

summary(VA_select)

VA_test_A <- predict(VA_select, X_test)

corn_VA_accuracy <- corn_test_A %>% cbind(VA_test_A)

corn_VA_accuracy %>% 
  ggplot(aes(x = Year, y = as.numeric(Value))) + 
  geom_line() + 
  geom_line(aes(y = results_test_A)) + 
  labs(title = "Model selection - train test",
       x = "Year",
       y = "Yield (bu/ac)") + 
  theme_classic()


results_VA_B <- predict(VA_select, corn_test_B)

corn_VA_accuracy_B <- corn_test_B %>% cbind(results_VA_B)

corn_VA_accuracy_B %>% 
  ggplot(aes(x = Year, y = as.numeric(Value))) + 
  geom_line() + 
  geom_line(aes(y = results_test_B)) + 
    labs(title = "Model selection - test set",
       x = "Year",
       y = "Yield (bu/ac)") + 
  theme_classic()


```
```{r}

VA_select <- lm(Value ~ Year + Apr_prec + Apr_sp01 + Jun_sp01, corn_test_A)

summary(VA_select)

X_test = corn_test_A %>%  select(Year, Apr_prec,  Apr_sp01, Jun_sp01)

VA_test_A <- predict(VA_select, X_test)

corn_VA_accuracy <- corn_test_A %>% cbind(VA_test_A)

corn_VA_accuracy %>% 
  ggplot(aes(x = Year, y = as.numeric(Value))) + 
  geom_line() + 
  geom_line(aes(y = results_test_A)) + 
  labs(title = "Model selection - train test",
       x = "Year",
       y = "Yield (bu/ac)") + 
  theme_classic()


results_VA_B <- predict(VA_select, corn_test_B)

corn_VA_accuracy_B <- corn_test_B %>% cbind(results_VA_B)

corn_VA_accuracy_B %>% 
  ggplot(aes(x = Year, y = as.numeric(Value))) + 
  geom_line() + 
  geom_line(aes(y = results_test_B)) + 
    labs(title = "Model selection - test set",
       x = "Year",
       y = "Yield (bu/ac)") + 
  theme_classic()

```

# scenarios

```{r}

Apr_prec_sc <- ts(corn_test$Apr_prec, start = 1980, end = 2024)
Apr_sp01_sc <- ts(corn_test$Apr_sp01, start = 1980, end = 2024)
Jun_sp01_sc <- ts(corn_test$Jun_sp01, start = 1980, end = 2024)

Apr_prec_model <- auto.arima(Apr_prec_sc)
Apr_sp01_model <- auto.arima(Apr_sp01_sc)
Jun_sp01_model <- auto.arima(Jun_sp01_sc)

Apr_prec_fc <- forecast(Apr_prec_model, level = 95, h = 15)
Apr_sp01_fc <- forecast(Apr_sp01_model, level = 95, h = 15)
Jun_sp01_fc <- forecast(Jun_sp01_model, level = 95, h = 15)

autoplot(Apr_prec_fc)
autoplot(Apr_sp01_fc)
autoplot(Jun_sp01_fc)


```

```{r}

baseline <- data.frame(Year = seq(from = 2025, to = 2039, by = 1),
                       Apr_prec = Apr_prec_fc$mean,
                       Apr_sp01 = Apr_sp01_fc$mean,
                       Jun_sp01 = Jun_sp01_fc$mean)

high <- data.frame(Year = seq(from = 2025, to = 2039, by = 1),
                   Apr_prec_fc$upper,
                   Apr_sp01_fc$upper,
                   Jun_sp01_fc$upper) %>% 
  dplyr::rename("Apr_prec" = "X95.",
                "Apr_sp01" = "X95..1",
                "Jun_sp01" = "X95..2")

low <- data.frame(Year = seq(from = 2025, to = 2039, by = 1),
                  Apr_prec = Apr_prec_fc$lower,
                  Apr_sp01 = Apr_sp01_fc$lower,
                  Jun_sp01 = Jun_sp01_fc$lower) %>% 
  dplyr::rename("Apr_prec" = "X95.",
                "Apr_sp01" = "X95..1",
                "Jun_sp01" = "X95..2")



```

```{r}

baseline_result <- predict(VA_select, baseline)

high_result <- predict(VA_select, high)

low_result <- predict(VA_select, low)

scenario_final <- data.frame(Year = seq(from = 2025, to = 2039, by = 1),
                             Value = NA,
                             baseline = baseline_result,
                             high = high_result,
                             low = low_result)

historic <- corn_test %>% select(Year, Value) %>% 
  mutate(Value = as.numeric(Value),
         baseline = NA,
         high = NA,
         low = NA)

finaldf <- bind_rows(historic, scenario_final)

finaldf %>% ggplot(aes(x = Year)) + 
  geom_line(aes(y = Value)) + 
  geom_line(aes(y = baseline, color = "baseline")) +
  geom_line(aes(y = high, color = "High")) + 
  geom_line(aes(y = low, color = "Low")) + 
  labs(title = "VA corn yield scenarios",
       x = "Year",
       y = "Yield") + 
  theme_classic()



```

**VAR Model**
```{r}
#DATASET IMPORT
url <- "https://raw.githubusercontent.com/jtwhamond/VT-capstone-project/refs/heads/main/CapstoneData.csv?token=GHSAT0AAAAAADH5GBJWLLDIDQXWI3FUAC2I2EFCXTA"
va.corn.data <- read.csv(url)
```

```{r}
#create time series
VA.YLD.RAW <- ts(va.corn.data$VA.YLD, start = 1980, end=2024, frequency = 1)
VA.RPRICE.RAW <- ts(va.corn.data$REAL.VA.PRICE, start = 1980, end = 2024, frequency =1)
```

```{r}
#Linear Regression Recap/Variable Significance
temp.va.24 <- head(temp_va, -1)
prec.va.24 <- head(prec_va, -1)
sp01.va.24 <- head(sp01_va, -1)
add_weather <- cbind(va.corn.data,temp.va.24,prec.va.24,sp01.va.24)
add_weather$TREND <- seq_along(va.corn.data$YEAR) # create trend variable starting with count 1 = 1980
```
```{r}
#Regression continued
yld.reg.1 <- lm(VA.YLD ~ TREND + Apr_temp + Apr_prec + May_temp + May_prec + Jun_temp + Jun_prec + Jul_temp + Jul_prec + Aug_temp + Aug_prec + Sep_temp + Sep_prec 
                +Sep_sp01 + Aug_sp01 + Jul_sp01 + Jun_sp01 + May_sp01, data = add_weather)
stargazer(yld.reg.1,
          type = "text",
          report = "vcsp",
          title = "VA Corn Yield Trend Model 1 - All Variables",
          digits = 3,
          style = "default",
          intercept.bottom = FALSE)
```
```{r}
#Model with selected variables - highest significance 
yld.reg.2 <- lm(VA.YLD ~ TREND + Jun_sp01 + Jul_prec + I(Jul_prec^2) + Jul_sp01 + Aug_temp, data = add_weather)
stargazer(yld.reg.2,
          type = "text",
          report = "vcsp",
          title = "VA Corn Yield Trend Model 2 - Select Variables",
          digits = 3,
          style = "default",
          intercept.bottom = FALSE)
```
Above models are on entire dataset. Need to train a model to perform well on unseen data.

```{r}
#Run model on a training set 1980 to 2014
lr.train <- add_weather[add_weather$YEAR <= 2014, ]
lr.test <- add_weather[add_weather$YEAR > 2014, ]
```

```{r}
#Run Model Wide Open Again to Reassess significant variables
yld.reg.3 <- lm(VA.YLD ~ TREND + Apr_temp + Apr_prec + May_temp + May_prec + Jun_temp + Jun_prec + Jul_temp + Jul_prec + Aug_temp + Aug_prec + Sep_temp + Sep_prec 
                +Sep_sp01 + Aug_sp01 + Jul_sp01 + Jun_sp01 + May_sp01, data = lr.train)
stargazer(yld.reg.3,
          type = "text",
          report = "vcsp",
          title = "VA Corn Yield Trend Model 3 - All Variables on Train Set 1980-2014",
          digits = 3,
          style = "default",
          intercept.bottom = FALSE)
```
Trend + Apr_prec + Jul_temp + Jul_prec + Aug_temp + Sep_temp + Sep_prec + Jul_sp01 + Sep_sp01 = significant 5% 


```{r}
#Trim Model by only including above significant variables
yld.reg.4 <- lm(VA.YLD ~ TREND  + Apr_prec + May_prec + Jun_prec + Jul_temp + Jul_prec + I(Jul_prec^2) + Aug_temp, data = lr.train) #MODEL USED FOR FORMAL TESTING VS VARX
stargazer(yld.reg.4,
          type = "text",
          report = "vcsp",
          title = "VA Corn Yield Trend Model 4 - Select Variables On Train Set 1980-2014",
          digits = 3,
          style = "default",
          intercept.bottom = FALSE)
```
```{r}
#including all key month weather variables to compare parsimony/fit
yld.reg.5 <- lm(VA.YLD ~ TREND + Apr_prec + Apr_temp + May_temp + May_prec +Jun_temp +Jun_prec +Jul_temp +Jul_prec + I(Jul_prec^2) + Aug_temp + Aug_prec, data = lr.train)
#AIC/BIC Test for Parsimony at expense of fit
AIC(yld.reg.4, yld.reg.5)
BIC(yld.reg.4,yld.reg.5)
```
yld reg 4 model variables offer a decent level of explanatory power with less variables, which is preferred. 

```{r}
#Predict over Test Set
test.yld.ts <- ts(lr.test$VA.YLD, start =2015, end = 2024)
yld.fcast.test <- ts(predict(yld.reg.4, lr.test), start = 2015, end = 2024)
autoplot(yld.fcast.test, series = "Linear Model - Virginia Corn Yields 2015-2024") +
  autolayer(test.yld.ts, series = "Test Set Yield") +
  labs(title = "Linear Regression Over Test Period 2015-2024", y = "Yield (BPA)") +
  scale_color_manual(values = c("blue","black")) +
  theme_minimal()

```
```{r}
#Get errors 
lin.reg.acc <- accuracy(yld.fcast.test, test.yld.ts)
lr.RMSE <- lin.reg.acc["Test set", "RMSE"]
lr.MAPE <- lin.reg.acc["Test set","MAPE"]
lr.MSE <- lr.RMSE^2
lr.acc <- c("MSE"=lr.MSE,"RMSE"=lr.RMSE, "MAPE"=lr.MAPE)
knitr::kable(cbind('Lin. Reg'=lr.acc),
             format.args = list(big.mark = ","),
             caption = "Linear Model Accuracy")
```


#VARMODEL
```{r}
#data visuals
c1 <- autoplot(VA.YLD.RAW) + labs(y="Bushels Per Acre", x = "Year", title = "Virginia Corn Yield 1980-2024") +geom_point()
c2 <- ggAcf(VA.YLD.RAW)
gridExtra::grid.arrange(c1,c2,ncol=1)
```
```{r}
#test stationarity for yield
VA.YLD.RAW %>% tseries::kpss.test()
```
P-value = 0.01, reject the null hypothesis of stationarity in data. Need to transform. 
```{r}
#Difference the Yield Data
VA.YLD.D1 <- VA.YLD.RAW %>% diff()
VA.YLD.D1 %>% autoplot()
```
```{r}
#kpss test again 
VA.YLD.D1 %>% tseries::kpss.test()
VA.YLD.D1 %>% tseries::adf.test()
```
P-value = 0.10, fail to reject null hypothesis at 10% significance. Data is stationary and ready for VAR

```{r}
#repeat for real prices
#visualization first
c3 <- autoplot(VA.RPRICE.RAW) + labs(title = "Real Virginia Price Recieved For Corn 1980-2024", y= "$/Bushel", x ="Year") + geom_point()
c4 <- ggAcf(VA.RPRICE.RAW)
gridExtra::grid.arrange(c3,c4,ncol=1)
```
```{r}
#KPSS test for stationarity 
VA.RPRICE.RAW %>% tseries::kpss.test()
VA.RPRICE.RAW %>% tseries::adf.test()
```
Data is stationary based on test p-values.

```{r}
#organize Y variables into correct length/split into training and test sets
VA.RPRICE.2 <- window(VA.RPRICE.RAW, start = 1980)
price.train <- window(VA.RPRICE.2, start = 1980, end = 2014)
price.test <- window(VA.RPRICE.2, start = 2015, end = 2024)
yld.train.stat <- window(VA.YLD.D1, start = 1981, end=2014)
yld.test.stat <- window(VA.YLD.D1, start = 2015, end = 2024)
Y.train.stat <- cbind(yld.train, price.train)
Y.test.stat <- cbind(yld.test, price.test)
yld.train <- window(VA.YLD.RAW, start = 1980, end = 2014)
yld.test <- window(VA.YLD.RAW, start = 2015, end = 2024)
Y.train <- cbind(yld.train, price.train)
Y.test <- cbind(yld.test,price.test)
X <- add_weather[add_weather$year >= 1980 & add_weather$year <= 2024, 
                 c("year", "apr_prec", "may_prec", "jun_prec", 
                   "jul_temp", "jul_prec", "aug_temp", 
                   "trend", "avg_extreme_days")]
X$jul_prec2 <- X$jul_prec^2
years <- 1980:2024
X <- data.frame(year = as.numeric(years), X)
X.train.1 <- subset(X, year <= 2014)
X.test.1 <- subset(X, year > 2014)
X.train <- X.train.1[, !(names(X.train.1) %in% c("year", "year.1"))]
X.test  <- X.test.1[, !(names(X.test.1) %in% c("year", "year.1"))]
```

```{r}
names(add_weather)
```

```{r}
#test for stationarity among exogenous dataframe
library(tseries)
adf.test(X$jul_prec)
adf.test(X$jul_prec2)
adf.test(X$jun_sp01)
adf.test(X$aug_temp)
adf.test(X$jul_sp01)
adf.test(X$jul_temp)

```
Jun_sp01, Aug_temp, Jul_temp not stationary. 

```{r}
#difference nonstationary series
X.diff <- data.frame(
jun_sp01.diff <- diff(X$jun_sp01),
aug_temp.diff <- diff(X$aug_temp),
jul_temp.diff <- diff(X$jul_temp))
```
```{r}
#retest for stationarity 
adf.test(X.diff$Jun_sp01.diff)
adf.test(X.diff$Jul_temp.diff)
adf.test(X.diff$Aug_temp.diff)
```

Data is stationary. *We later discussed and decided that we did not need to be concerned with stationarity of the series due to the nature of our analysis. So decided to 
use the variables as is for our VARX model* 


**VARX**
```{r}
#RUN VARX Model
library(vars)
VARselect(Y.train, lag.max = 10, type = "const", exogen = X.train) #optimize VARX lag value, P
```
```{r}
#continue VARX Model
va.varx <- VAR(y=Y.train, p = 1  , exogen = X.train, type = "const") ##VARX MODEL 
summary(va.varx)
```

```{r}
#Plot VARX MODEL YIELDS
va.varx.fitted <- fitted(va.varx)
va.varx.yld.fitted <- ts(va.varx.fitted[,1], start = 1981, end=2014, frequency =1)
autoplot(yld.train, series = "Training Data") +
  autolayer(va.varx.yld.fitted, series = "Fitted Values") +
  labs(title = "Training Data with VARX Fitted Values", y = "Yield (BPA)") +
  scale_color_manual(values = c("blue","black")) +
  theme_minimal()+ theme(legend.position = "bottom")

```
```{r}
#Plot VARX MODEL Prices
va.varx.fitted <- fitted(va.varx)
va.varx.yld.fitted <- ts(va.varx.fitted[,2], start = 1981, end=2014, frequency =1)
autoplot(price.train, series = "Training Data") +
  autolayer(va.varx.yld.fitted, series = "Fitted Values") +
  labs(title = "Training Data with VARX Fitted Price", y = "Price ($/bu)") +
  scale_color_manual(values = c("blue","black")) +
  theme_minimal()+ theme(legend.position = "bottom")
```

```{r}
Box.test(var.x.resid[,"price.train"], lag = 10, type = "Ljung-Box")
```

```{r}
#Check Residuals
var.x.resid <- residuals(va.varx)
Box.test(var.x.resid[,"yld.train"], lag = 10, type = "Ljung-Box")
```
**Fail to reject** null hypothesis of no autocorrelation. Residuals resemble white noise. 

```{r}
#Forecast over Test Set
VARX.FCast <- predict(va.varx, n.ahead = 10, dumvar = X.test)
YLD.FCast <- ts(VARX.FCast$fcst$yld.train[,"fcst"],start = 2015, end = 2024, frequency =1)
#plot forecasts over test set
autoplot(YLD.FCast, series = "Forecast Over Test Set") +
  autolayer(yld.test, series = "Test Set-VA Corn Yields 2015-2024") +
  labs(title = "Estimation Over Test Data", y = "Yield (BPA)") +
  scale_color_manual(values = c("blue","black")) +
  theme_minimal()+ theme(legend.position = "bottom")
```
```{r}
print(YLD.FCast)
```

```{r}
PRICE.FCast <- ts(VARX.FCast$fcst$price.train[, "fcst"], start = 2015, end =2024, frequency =1)
#plot
autoplot(PRICE.FCast, series = "Price Forecast Over Test Set") +
  autolayer(price.test, series = "Test Set-VA Corn Yields 2015-2024") +
  labs(title = "Estimation Over Test Data", y = "Yield (BPA)") +
  scale_color_manual(values = c("blue","black")) +
  theme_minimal()+ theme(legend.position = "bottom")
```
```{r}
print(PRICE.FCast)
print(price.test)
```


```{r}
#Model Accuracy over Test set - Prices
varx.accuracy <- accuracy(PRICE.FCast,price.test)
varx.RMSE <- varx.accuracy["Test set","RMSE"]
varx.MSE <- varx.RMSE^2
varx.MAPE <- varx.accuracy["Test set","MAPE"]
varx.acc <- c("MSE"=varx.MSE,"RMSE"=varx.RMSE,"MAPE"=varx.MAPE)
knitr::kable(cbind('VARX'=varx.acc),
             format.args = list(big.mark=","),
             caption = "Model Accuracy")
```

```{r}
#Model Accuracy over Test set - Yields
varx.accuracy <- accuracy(YLD.FCast,yld.test)
varx.RMSE <- varx.accuracy["Test set","RMSE"]
varx.MSE <- varx.RMSE^2
varx.MAPE <- varx.accuracy["Test set","MAPE"]
varx.acc <- c("MSE"=varx.MSE,"RMSE"=varx.RMSE,"MAPE"=varx.MAPE)
knitr::kable(cbind('VARX'=varx.acc),
             format.args = list(big.mark=","),
             caption = "Model Accuracy")
```


```{r}
url1 <- "https://raw.githubusercontent.com/jtwhamond/VT-capstone-project/refs/heads/main/10Y%20Rolling%20Average%20Weather%20Variables%20For%2010%20Year%20Forecast.csv?token=GHSAT0AAAAAADH5GBJXHWKZRZMPSSOBJDX62ESXKCQ"

rolling.avg.fcast <- read.csv(url1)
```


```{r}
X.clean <-X[ , !(names(X) %in% c("year","year.1"))]
full.dat <- add_weather[add_weather$year <=2024]
Y <- ts(cbind(VA.YLD.RAW, VA.RPRICE.RAW), start = 1980, end= 2024)
va.varx.full <- VAR(y=Y, p = 1, exogen = X.clean, type = "const") ##VARX MODEL ON FULL DATA
exog.fcast <- rolling.avg.fcast[, c("Apr_prec","May_prec","Jun_prec","Jul_temp","Jul_prec","Aug_temp")]
exog.fcast$Jul_prec2 <- rolling.avg.fcast$Jul_prec^2
X.fcast <- tail(exog.fcast, 10)
X.fcast$TREND <- 46:55
X.fcast$avg_extreme_days <- c(7.96, 7.86, 7.47, 7.48, 7.53, 7.43, 7.59, 7.56, 7.6, 8.02) #manually add extreme heat averages
names(X.fcast) <- tolower(names(X.fcast)) 
X.fcast <- X.fcast[, names(X.clean)]
```

```{r}
summary(va.varx.full)
```

```{r}

VARX.FCast.10Y <- predict(va.varx.full, n.ahead = 10, dumvar = X.fcast)
print(VARX.FCast.10Y)
```

```{r}
YLD.FCast.10Y <- ts(VARX.FCast.10Y$fcst$VA.YLD.RAW[,"fcst"],start = 2025, end = 2034, frequency =1)
YLD.FCast.hi <- ts(VARX.FCast.10Y$fcst$VA.YLD.RAW[,"upper"], start = 2025, end = 2034, frequency =1)
YLD.FCast.lo <- ts(VARX.FCast.10Y$fcst$VA.YLD.RAW[,"lower"], start = 2025, end = 2034, frequency =1)

#Plot forecasts over test and 10 years into the future
autoplot(YLD.FCast.10Y, series = "Model Forecast") +
  autolayer(VA.YLD.RAW, series = "VA Corn Yields 1980-2024") +
  autolayer(YLD.FCast.hi) +
  autolayer(YLD.FCast.lo) +
  labs(title = "10-Year Virginia Corn Yield Forecast Assuming Average Weather", y = "Yield (BPA)") +
  scale_color_manual(values = c("blue","black","red","green")) +
  theme_minimal() + theme(legend.position = "bottom")
```
**PRICE FORECASTS**

```{r, fig.width=8}
PR.FCast.10Y <- ts(VARX.FCast.10Y$fcst$VA.RPRICE.RAW[,"fcst"],start = 2025, end = 2034, frequency =1)
PR.FCast.hi <- ts(VARX.FCast.10Y$fcst$VA.RPRICE.RAW[,"upper"], start = 2025, end = 2034, frequency =1)
PR.FCast.lo <- ts(VARX.FCast.10Y$fcst$VA.RPRICE.RAW[,"lower"], start = 2025, end = 2034, frequency =1)

#Plot forecasts over test and 10 years into the future
autoplot(PR.FCast.10Y, series = "Model Forecast") +
  autolayer(VA.RPRICE.RAW, series = "VA Corn Prices (Inflation Adjusted) 1980-2024") +
  autolayer(PR.FCast.hi) +
  autolayer(PR.FCast.lo) +
  labs(title = "10-Year Virginia Corn Price Forecast Assuming Average Weather", y = "Price ($/Bushel)") +
  scale_color_manual(values = c("blue","black","red","green")) +
  theme_minimal() + theme(legend.position = "bottom")
```


**IMPULSE RESPONSE FUNCTION**
```{r}
#Measuring yield response to shock
irf.yld <- irf(va.varx.full, impulse = "VA.YLD.RAW", response = c("VA.YLD.RAW", "VA.RPRICE.RAW"), boot = TRUE, runs = 1000) #look into bootstrap number/iterations
#Measuring price response to shock 
irf.price <- irf(va.varx.full, impulse = "VA.RPRICE.RAW", response = c("VA.RPRICE.RAW", "VA.YLD.RAW"), boot = TRUE, runs = 1000)
```
```{r}
print(irf.yld)
print(irf.price)
```



```{r, fig.height = 8, fig.width = 8}
# Set outer margins: Bottom, Left, Top, Right
par(oma = c(5, 4, 4, 2))  # top margin increased to make space

# Plot with default subplot titles (can’t suppress them reliably)
plot(irf.yld, 
     ylab = "",
     xlab = "",
     ylim = c(-5, 10)
)

# Add your custom title and axis labels BELOW the subplot titles
title(main = "Impulse Response of Shock to Corn Yield", outer = TRUE, line = 1)
mtext("Years Following Shock", side = 1, outer = TRUE, line = 2)
mtext("Response to Shock", side = 2, outer = TRUE, line = 2)
     
```


```{r, fig.height = 8, fig.width = 8}
plot(irf.price)
```
```{r}
packageVersion("vars")
```

**Model with County Weighted Weather**
```{r}
# Load county-level weather data from Excel
url3 <- "https://raw.githubusercontent.com/jtwhamond/VT-capstone-project/refs/heads/main/County%20Level%20Weather%20Data%20CSV.csv?token=GHSAT0AAAAAADH5GBJXRMHKIIRC6ZGLY7662ESRU7A"

weather_raw <- read.csv(url3)
```

```{r}
# Map station names to counties
station_to_county <- tribble(
  ~station_name,                      ~county,
  "DALE ENTERPRISE",                 "ROCKINGHAM",
  "STAUNTON WATER TREATMENT PLANT", "AUGUSTA",
  "HOLLAND 1 E",                     "SOUTHAMPTON",
  "ONLEY0.6 SE",                     "ACCOMACK",
  "WALKERTON 2 NW",                  "ESSEX",
  "MANASSAS",                        "FAUQUIER",
  "ROCKY MOUNT",                     "FRANKLIN",
  "MONTROSS 5.2 ESE",                "WESTMORELAND",
  "SUFFOLK 13.9 NNE",                "SUFFOLK CITY",
  "HEATHSVILLE 4.6 SE",              "NORTHUMBERLAND"
)

# Clean and prepare weather data
library(lubridate)

weather_clean <- weather_raw %>%
  mutate(
    station_name = str_remove(NAME, ", VA US") |> toupper(),
    date = as.Date(DATE, format = "%m/%d/%Y"),
    year = year(date),
    month = month(date),
    tmax_F = TMAX,
    tmin_F = TMIN,
    prcp_inches = PRCP / 100
  ) %>%
  left_join(station_to_county, by = "station_name") %>%
  filter(!is.na(county), month %in% 4:8, year >= 1980)
```


```{r}
# Summarize heat metrics per county and year
county_weather_metrics <- weather_clean %>%
  filter(month %in% 4:8) %>%
  group_by(county, year) %>%
  summarise(
    avg_temp_Jul = mean(tmax_F[month == 7], na.rm = TRUE),
    avg_precip_Jul = sum(prcp_inches[month == 7], na.rm = TRUE),
    total_hot_days = sum(tmax_F >= 94, na.rm = TRUE),
    avg_extreme_temp = mean(tmax_F[tmax_F >= 94], na.rm = TRUE),
    mod_temp_days = sum(tmax_F < 91.4, na.rm = TRUE),
    extreme_temp_days = sum(tmax_F >= 91.4, na.rm = TRUE),
    .groups = "drop"
  )
```

```{r}
library(janitor)
url4 <- "https://raw.githubusercontent.com/jtwhamond/VT-capstone-project/refs/heads/main/County%20Weights%20CSV.csv"
weights_df <- read.csv(url4) %>%
  clean_names() %>% 
  rename(
    acres_planted = acres_planted_1980_2024,
    percent_state_total = percent_of_state_total,
    weight = weights
  ) %>%
  mutate(
    county = toupper(county),       # match naming in weather data
    weight = as.numeric(weight) / 100           # convert from percent to proportion (e.g., 106 → 1.06)
  )
```
```{r}
url4 <- "https://raw.githubusercontent.com/jtwhamond/VT-capstone-project/refs/heads/main/County%20Weights%20CSV.csv"
weights_df <- read.csv(url4) %>%
  clean_names() %>% 
  rename(
    acres_planted = acres_planted_1980_2024,
    percent_state_total = percent_of_state_total
  ) %>%
  mutate(
    county = toupper(trimws(county)),
    percent_state_total = as.numeric(str_remove(percent_state_total, "%")),
    weight = percent_state_total / 100
  )
```

```{r}
#create average extreme weather days by year
county_weather_metrics <- county_weather_metrics %>%
  mutate(county = toupper(trimws(county)))

yearly_avg_extreme_temp <- county_weather_metrics %>% group_by(year) %>% summarise(avg_extreme_days = mean(extreme_temp_days, na.rm = TRUE))
```

```{r}
add_weather <- add_weather %>% left_join(yearly_avg_extreme_temp, by = "year")
```

```{r}

```





